{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd07a379f6021147b60a0af445b7b971749dec1c9727e2f52e01b69fbcef0cfcb28",
   "display_name": "Python 3.8.5 64-bit ('bangkit': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7a379f6021147b60a0af445b7b971749dec1c9727e2f52e01b69fbcef0cfcb28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Prepare the Web Driver"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The tutorial is from https://towardsdatascience.com/image-scraping-with-python-a96feda8af2d"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# This is the path I use\n",
    "# DRIVER_PATH = '.../Desktop/Scraping/chromedriver 2'\n",
    "# Put the path for your ChromeDriver here\n",
    "# If this error occurs: WebDriverException: Message: 'Webdrivers' executable may have wrong permissions.\n",
    "## See this post: https://stackoverflow.com/questions/47148872/webdrivers-executable-may-have-wrong-permissions-please-see-https-sites-goo\n",
    "\n",
    "DRIVER_PATH = '/home/shin/Bangkit Academy/CAPSTONE PROJECT/chromedriver_linux64/chromedriver'\n",
    "wd = webdriver.Chrome(executable_path=DRIVER_PATH)"
   ]
  },
  {
   "source": [
    "Scrap Informations from URLs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fetch_infos(queries:str, wd:webdriver):\n",
    "    infos = []\n",
    "    \n",
    "    for query in queries:\n",
    "        # build the google query\n",
    "        search_url = \"https://google.com/search?safe=off&site=&q={q}&language=id\"\n",
    "\n",
    "        # load the page\n",
    "        wd.get(search_url.format(q=query))\n",
    "\n",
    "\n",
    "        info = {}\n",
    "        try:\n",
    "            infobox = wd.find_elements_by_id(\"wp-tabs-container\")[0]\n",
    "        \n",
    "            # title\n",
    "            title = infobox.find_elements_by_tag_name('h2')[0]\n",
    "            info['title'] = title.text\n",
    "\n",
    "            # description\n",
    "            desc = infobox.find_elements_by_class_name('kno-rdesc')[0].find_elements_by_tag_name('span')[0]\n",
    "            info['desc'] = desc.text\n",
    "\n",
    "            # scientific name\n",
    "            sn = infobox.find_elements_by_class_name('kno-fv')[0]\n",
    "            info['scientific_name'] = sn.text\n",
    "\n",
    "            # source\n",
    "            src = infobox.find_elements_by_class_name('fl')[0]\n",
    "            info['source'] = src.get_attribute('href')\n",
    "\n",
    "            # images sample\n",
    "            num = 4\n",
    "            img_urls = []\n",
    "            imgs = infobox.find_elements_by_tag_name('img')\n",
    "            for im in imgs[:num]:\n",
    "                link = im.get_attribute('src')\n",
    "                img_urls.append(link)\n",
    "            info['img_urls'] = img_urls\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        infos.append(info)\n",
    "        time.sleep(1)\n",
    "\n",
    "        print(f'DONE: {query}')\n",
    "\n",
    "    return infos"
   ]
  },
  {
   "source": [
    "## Read list of keywords to search from file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DONE: anggrek\n",
      "DONE: mawar\n",
      "DONE: melati\n",
      "DONE: mangga\n",
      "DONE: kelapa\n",
      "DONE: singkong\n",
      "DONE: ubi jalar\n",
      "DONE: tebu\n",
      "DONE: padi\n",
      "DONE: bayam\n",
      "DONE: jambu\n",
      "DONE: teratai\n",
      "DONE: lidah buaya\n",
      "DONE: bengkuang\n",
      "DONE: ceremai\n",
      "DONE: cempaka\n",
      "DONE: ciplukan\n",
      "DONE: durian\n",
      "DONE: mengkudu\n",
      "DONE: sirih\n",
      "DONE: gambir\n",
      "DONE: alpukat\n",
      "DONE: apel\n",
      "DONE: maja\n",
      "DONE: jati\n",
      "DONE: karet\n",
      "DONE: kenanga\n",
      "DONE: kapuk randu\n",
      "DONE: gaharu\n",
      "DONE: matoa\n",
      "DONE: nibung\n",
      "DONE: delima\n",
      "DONE: belimbing\n",
      "DONE: jeruk\n",
      "DONE: manggis\n",
      "DONE: pisang\n",
      "DONE: nangka\n",
      "DONE: rambutan\n",
      "DONE: pepaya\n",
      "DONE: sawo\n",
      "DONE: cabai\n",
      "DONE: cengkeh\n",
      "DONE: kencur\n",
      "DONE: jahe\n",
      "DONE: lada\n",
      "DONE: pala\n",
      "DONE: kentang\n",
      "DONE: terung\n",
      "DONE: kacang tanah\n",
      "DONE: kacang hijau\n"
     ]
    }
   ],
   "source": [
    "lines=[]\n",
    "with open('nama_tumbuhan.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "queries = list(map(lambda x: x.strip(), lines))\n",
    "infos = fetch_infos(queries, wd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'writeline'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-6b473a6e16d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[x] no {key}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'writeline'"
     ]
    }
   ],
   "source": [
    "keys = ['title', 'desc', 'scientific_name']\n",
    "with open('logs', 'w') as f:\n",
    "    for info in infos:\n",
    "        for key in keys:\n",
    "            if key in info:\n",
    "                f.writeln(info[key])\n",
    "            else:\n",
    "                print(f'[x] no {key}')\n",
    "        if 'img_urls' in info:\n",
    "            f.writeln(len(info['img_urls']))\n",
    "        else:\n",
    "            f.writeln('[x] no images')\n",
    "        f.writeln('----')"
   ]
  },
  {
   "source": [
    "# Save Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "def save_images(urls:str, folder:str):\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "    except:\n",
    "        pass\n",
    "    for i, url in enumerate(urls):\n",
    "        head, data = url.split(',')\n",
    "        image_data = base64.b64decode(data)\n",
    "\n",
    "        file_path = os.path.join(folder, f'{i}.jpg')\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ERROR at index 4 : 'img_urls'\nERROR at index 7 : 'img_urls'\nERROR at index 8 : not enough values to unpack (expected 2, got 1)\nERROR at index 12 : not enough values to unpack (expected 2, got 1)\nERROR at index 15 : 'img_urls'\nERROR at index 19 : not enough values to unpack (expected 2, got 1)\nERROR at index 23 : not enough values to unpack (expected 2, got 1)\nERROR at index 25 : 'img_urls'\nERROR at index 28 : 'img_urls'\nERROR at index 35 : 'img_urls'\nERROR at index 40 : 'img_urls'\nERROR at index 45 : 'img_urls'\nERROR at index 46 : 'title'\nERROR at index 48 : 'img_urls'\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'wiki_images'\n",
    "for i, item in enumerate(infos):\n",
    "    try:\n",
    "        title = item['title']\n",
    "        imgs = item['img_urls']\n",
    "        folder = os.path.join(parent_dir, title)\n",
    "        save_images(imgs, folder)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR at index {i} : {e}')"
   ]
  },
  {
   "source": [
    "# Save the Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('info.json', 'w') as f:\n",
    "    for info in infos:\n",
    "        "
   ]
  },
  {
   "source": [
    "# Close the Web Driver"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.close()"
   ]
  }
 ]
}